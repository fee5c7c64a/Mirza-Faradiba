{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaWoFZfrlr9xhhfcgLvCkk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirzafaradiba01/Mirza-Faradiba/blob/main/14_Mirza_Priscilla_Faradiba_Jobsheet_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YZOlg_nazIj",
        "outputId": "4f30d0ee-cf25-437e-ad11-4728a47563a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'outlook': -0.03066463578403711,\n",
              " 'temp': -0.06863218379564806,\n",
              " 'humidity': 0.29277376971072666,\n",
              " 'windy': 0.23746642755584824}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#PRAKTIKUM\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "eps = np.finfo(float).eps\n",
        "from numpy import log2 as log\n",
        "\n",
        "outlook = 'overcast,overcast,overcast,overcast,rainy,rainy,rainy,rainy,rainy,sunny,sunny,sunny,sunny,sunny'.split(',')\n",
        "temp = 'hot,cool,mild,hot,mild,cool,cool,mild,mild,hot,hot,mild,cool,mild'.split(',')\n",
        "humidity = 'high,normal,high,normal,high,normal,normal,normal,high,high,high,high,normal,normal'.split(',')\n",
        "windy = 'FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE'.split(',')\n",
        "play = 'yes,yes,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes'.split(',')\n",
        "\n",
        "dataset ={'outlook':outlook,'temp':temp,'humidity':humidity,'windy':windy,'play':play}\n",
        "df = pd.DataFrame(dataset,columns=['outlook','temp','humidity','windy','play'])\n",
        "\n",
        "entrophy_node = 0\n",
        "values = df.play.unique()\n",
        "for value in values:\n",
        "    fraction = df.play.value_counts()[value]/len(df.play)\n",
        "    entrophy_node += -fraction*np.log2(fraction)\n",
        "entrophy_node\n",
        "\n",
        "def ent(df,attribute):\n",
        "    target_variables = df.play.unique()\n",
        "    variables = df[attribute].unique()\n",
        "\n",
        "    entrophy_attribute = 0\n",
        "    for variable in variables:\n",
        "        entrophy_each_feature = 0\n",
        "        for target_variable in target_variables:\n",
        "            num = len(df[attribute][df[attribute]==variable][df.play ==target_variable])\n",
        "            den = len(df[attribute][df[attribute]==variable])\n",
        "            fraction = num/(den+eps)\n",
        "            entrophy_each_feature += -fraction*log(fraction+eps)\n",
        "        fraction2 = den/len(df)\n",
        "        entrophy_attribute += -fraction*entrophy_each_feature\n",
        "\n",
        "    return(abs(entrophy_attribute))\n",
        "\n",
        "a_entrophy = {k:ent(df,k) for k in df.keys()[:-1]}\n",
        "a_entrophy\n",
        "\n",
        "def ig(e_dataset,e_attr):\n",
        "    return(e_dataset-e_attr)\n",
        "\n",
        "IG = {k:ig(entrophy_node,a_entrophy[k]) for k in a_entrophy}\n",
        "IG\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "eps = np.finfo(float).eps\n",
        "from numpy import log2 as log\n",
        "\n",
        "outlook = 'overcast,overcast,overcast,overcast,rainy,rainy,rainy,rainy,rainy,sunny,sunny,sunny,sunny,sunny'.split(',')\n",
        "temp = 'hot,cool,mild,hot,mild,cool,cool,mild,mild,hot,hot,mild,cool,mild'.split(',')\n",
        "humidity = 'high,normal,high,normal,high,normal,normal,normal,high,high,high,high,normal,normal'.split(',')\n",
        "windy = 'FALSE,TRUE,TRUE,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,TRUE'.split(',')\n",
        "play = 'yes,yes,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes'.split(',')\n",
        "\n",
        "dataset ={'outlook':outlook,'temp':temp,'humidity':humidity,'windy':windy,'play':play}\n",
        "df = pd.DataFrame(dataset,columns=['outlook','temp','humidity','windy','play'])\n",
        "\n",
        "def find_entropy(df):\n",
        "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
        "    entropy = 0\n",
        "    values = df[Class].unique()\n",
        "    for value in values:\n",
        "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
        "        entropy += -fraction*np.log2(fraction)\n",
        "    return entropy\n",
        "  \n",
        "  \n",
        "def find_entropy_attribute(df,attribute):\n",
        "  Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
        "  target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
        "  variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
        "  entropy2 = 0\n",
        "  for variable in variables:\n",
        "      entropy = 0\n",
        "      for target_variable in target_variables:\n",
        "          num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
        "          den = len(df[attribute][df[attribute]==variable])\n",
        "          fraction = num/(den+eps)\n",
        "          entropy += -fraction*log(fraction+eps)\n",
        "      fraction2 = den/len(df)\n",
        "      entropy2 += -fraction2*entropy\n",
        "  return abs(entropy2)\n",
        "\n",
        "\n",
        "def find_winner(df):\n",
        "    Entropy_att = []\n",
        "    IG = []\n",
        "    for key in df.keys()[:-1]:\n",
        "#         Entropy_att.append(find_entropy_attribute(df,key))\n",
        "        IG.append(find_entropy(df)-find_entropy_attribute(df,key))\n",
        "    return df.keys()[:-1][np.argmax(IG)]\n",
        "  \n",
        "  \n",
        "def get_subtable(df, node,value):\n",
        "  return df[df[node] == value].reset_index(drop=True)\n",
        "\n",
        "\n",
        "def buildTree(df,tree=None): \n",
        "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
        "    \n",
        "    #Here we build our decision tree\n",
        "\n",
        "    #Get attribute with maximum information gain\n",
        "    node = find_winner(df)\n",
        "    \n",
        "    #Get distinct value of that attribute e.g Salary is node and Low,Med and High are values\n",
        "    attValue = np.unique(df[node])\n",
        "    \n",
        "    #Create an empty dictionary to create tree    \n",
        "    if tree is None:                    \n",
        "        tree={}\n",
        "        tree[node] = {}\n",
        "    \n",
        "   #We make loop to construct a tree by calling this function recursively. \n",
        "    #In this we check if the subset is pure and stops if it is pure. \n",
        "\n",
        "    for value in attValue:\n",
        "        \n",
        "        subtable = get_subtable(df,node,value)\n",
        "        clValue,counts = np.unique(subtable[Class],return_counts=True)                        \n",
        "        \n",
        "        if len(counts)==1:#Checking purity of subset\n",
        "            tree[node][value] = clValue[0]                                                    \n",
        "        else:        \n",
        "            tree[node][value] = buildTree(subtable) #Calling the function recursively \n",
        "                   \n",
        "    return tree"
      ],
      "metadata": {
        "id": "7gF6jVmXjs_y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pprintpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKMdRVFBqNFs",
        "outputId": "129dc8c8-9f3f-4ecf-f2ab-76360a64031f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pprintpp in /usr/local/lib/python3.7/dist-packages (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = buildTree(df)\n",
        "import pprint\n",
        "pprint.pprint(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00IJU90KqV0w",
        "outputId": "7419cfbc-68af-48d9-f36d-ebef79171a06"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'outlook': {'overcast': 'yes',\n",
            "             'rainy': {'windy': {'FALSE': 'yes', 'TRUE': 'no'}},\n",
            "             'sunny': {'humidity': {'high': 'no', 'normal': 'yes'}}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NAMA : MIRZA PRISCILLA FARADIBA\n",
        "KELAS : TI-2B\n",
        "NO ABS : 14\n",
        "NIM : 2141720254\n",
        "MATERI : DECISION TREE"
      ],
      "metadata": {
        "id": "P4ucwQQKv303"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}